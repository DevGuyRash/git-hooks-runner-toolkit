{
  "id": "snapshot_1761405278099_pyql6n8rw",
  "approvalId": "approval_1761405241565_iup3ah04n",
  "approvalTitle": "Approve testing-audit requirements (rev 2)",
  "version": 3,
  "timestamp": "2025-10-25T15:14:38.099Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Requirements Document\n\n## Introduction\n\nCreate a dedicated testing-audit initiative that reproduces the recent Ephemeral Mode anomaly (overlay roots logging truncated paths) and expands end-to-end coverage for every installer entry point, subcommand, and flag (including all `--help` surfaces). The work should catalogue all observed failures and gaps so follow-up fixes can be planned with clear evidence.\n\n## Alignment with Product Vision\n\nSupports the toolkit goal of providing dependable, policy-friendly Git hook automation by hardening the verification story for install flows, overlay precedence, and hook management behaviours.\n\n## Requirements\n\n### Requirement 1 — Install lifecycle verification matrix\n\n**User Story:** As a toolkit maintainer, I want a comprehensive matrix of both standard and ephemeral install/uninstall scenarios so that truncated overlay logs and similar regressions are documented with reproducible steps across every supported flag combination.\n\n#### Acceptance Criteria\n\n1. WHEN `install.sh install` is executed in both `standard` and `ephemeral` modes across vendored and shared-checkout contexts THEN the audit SHALL record hooks-path, overlay roots, file placements, and any mismatches (including truncated log output) with reproduction commands for every flag (`--hooks`, `--all-hooks`, `--overlay`, `--force`, `--dry-run`).\n2. IF Ephemeral Mode overlay resolution is invoked with each precedence (`ephemeral-first`, `versioned-first`, `merge`) THEN the audit SHALL capture the logged order alongside filesystem assertions for each root, and contrast behaviour with the standard mode equivalents.\n3. WHEN uninstall and reinstall cycles are exercised with custom `core.hooksPath` values set beforehand AND with additional flag permutations (`--dry-run`, `--mode` variations) THEN the audit SHALL document whether manifest restoration, log output, and exit codes stay consistent across runs.\n\n### Requirement 2 — CLI subcommand, flag, and help surface inventory\n\n**User Story:** As a release steward, I want an inventory of every CLI subcommand, legacy alias, and option (including `--help`/`help` variants) along with its automated coverage status so that we can prioritise missing or flaky cases.\n\n#### Acceptance Criteria\n\n1. WHEN reviewing `install`, `uninstall`, `stage`, `hooks`, `config`, and any nested subcommands THEN the audit SHALL enumerate all documented flags and `--help`/`help` outputs, note existing automated tests, and highlight gaps or behaviour changes observed during manual execution.\n2. IF a flag, subcommand, or help surface lacks automated verification THEN the audit SHALL include a failing or missing-test entry with suggested assertions, fixtures, or golden-output comparisons to add.\n3. WHEN legacy aliases (`init`, `add`, `remove`) and modern subcommands are invoked with `--help` and positional `help` THEN the audit SHALL explain current behaviour, coverage status, and any divergences versus expected output.\n\n### Requirement 3 — Test suite robustness and observability review\n\n**User Story:** As a quality engineer, I want actionable notes on improving the test harness so that failures like the overlay log truncation surface early with clear diagnostics.\n\n#### Acceptance Criteria\n\n1. WHEN auditing existing Bats and shell test helpers THEN the audit SHALL list brittleness points (environment dependencies, flaky setup, insufficient assertions) and proposed mitigations.\n2. IF additional logging or fixtures are required to capture overlay state, manifest contents, or CLI output THEN the audit SHALL describe these needs with concrete locations in the repo.\n3. WHEN summarising findings THEN the document SHALL recommend specific follow-up fixes or new tests to be scheduled as implementation tasks in the subsequent phase.\n\n## Non-Functional Requirements\n\n### Code Architecture and Modularity\n- Maintain separation between audit documentation, helper utilities, and future implementation changes so subsequent fixes can target scoped modules.\n- Ensure any proposed helper updates preserve the single-responsibility pattern used across `lib/` and `tests/helpers/`.\n\n### Performance\n- Audited test expansions SHOULD avoid introducing excessive runtime (target: end-to-end suite completes within current CI budget plus 10%).\n\n### Security\n- Audit steps MUST avoid exposing user-specific paths or secrets in committed artefacts; redact sensitive data when capturing logs.\n\n### Reliability\n- Findings MUST emphasise deterministic reproduction steps and required assertions so future fixes can be validated consistently across environments.\n\n### Usability\n- The resulting audit document SHOULD be consumable by contributors new to the toolkit, with clear command snippets and references to relevant scripts.\n",
  "fileStats": {
    "size": 4787,
    "lines": 60,
    "lastModified": "2025-10-25T15:13:56.079Z"
  },
  "comments": []
}